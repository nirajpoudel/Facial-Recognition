{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Facial Recognition_VGG19.ipynb","provenance":[],"mount_file_id":"1v3ZNvHxK052PzjI4pL5vAbXxrVXbqOC8","authorship_tag":"ABX9TyPIKVNmQ1axGx1XtdS69vyj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"q2vcAMHpizZy","executionInfo":{"status":"ok","timestamp":1614786058418,"user_tz":-345,"elapsed":3294,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}}},"source":["from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.applications.vgg19 import VGG19\n","from keras.applications.vgg19 import preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","import numpy as np\n","from glob import glob"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ItkWwcvjFek","executionInfo":{"status":"ok","timestamp":1614786058424,"user_tz":-345,"elapsed":3285,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}}},"source":["IMAGE_SIZE = [224, 224]\n","train_path = './drive/MyDrive/Facial Recognition/Datasets/train'\n","valid_path = './drive/MyDrive/Facial Recognition/Datasets/test'"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWcXCAZQjJCI","executionInfo":{"status":"ok","timestamp":1614786058429,"user_tz":-345,"elapsed":3282,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}}},"source":["# adding preprocessing layer to the front of VGG\n","vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0bhAZkXjMr1","executionInfo":{"status":"ok","timestamp":1614786058431,"user_tz":-345,"elapsed":3274,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}}},"source":["# skipping the existing weights to train\n","for layer in vgg.layers:\n","  layer.trainable = False"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"xV6Zz7ZgjSCI","executionInfo":{"status":"ok","timestamp":1614786058435,"user_tz":-345,"elapsed":3270,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}}},"source":["# getting the total number of classes using glob.\n","folders = glob('./drive/MyDrive/Facial Recognition/Datasets/train/*')"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rv796SfKjbQk","executionInfo":{"status":"ok","timestamp":1614786058436,"user_tz":-345,"elapsed":3265,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}}},"source":["x = Flatten()(vgg.output)\n","# x = Dense(1000, activation='relu')(x)\n","prediction = Dense(len(folders), activation='softmax')(x)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LsuGAcSjfCz","executionInfo":{"status":"ok","timestamp":1614786058440,"user_tz":-345,"elapsed":3262,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}},"outputId":"97141585-7ffa-4c99-f180-7c37b343259b"},"source":["# create a model object\n","model = Model(inputs=vgg.input, outputs=prediction)\n","# view the structure of the model\n","model.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 100356    \n","=================================================================\n","Total params: 20,124,740\n","Trainable params: 100,356\n","Non-trainable params: 20,024,384\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X_2rsT2ujiYy","executionInfo":{"status":"ok","timestamp":1614786058443,"user_tz":-345,"elapsed":3261,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}}},"source":["# tell the model what cost and optimization method to use\n","model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer='adam',\n","  metrics=['accuracy']\n",")"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUyXcABEjlz4","executionInfo":{"status":"ok","timestamp":1614786060048,"user_tz":-345,"elapsed":4855,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}},"outputId":"b2611881-5ae6-47db-8ccb-884f2f459c5d"},"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","training_set = train_datagen.flow_from_directory('./drive/MyDrive/Facial Recognition/Datasets/train',\n","                                                 target_size = (224, 224),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')\n","\n","test_set = test_datagen.flow_from_directory('./drive/MyDrive/Facial Recognition/Datasets/test',\n","                                            target_size = (224, 224),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Found 618 images belonging to 4 classes.\n","Found 120 images belonging to 4 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gUy7q1kxjn8m","executionInfo":{"status":"ok","timestamp":1614788462415,"user_tz":-345,"elapsed":408837,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}},"outputId":"3142d25a-3775-455d-e846-98b8d51d2171"},"source":["# fit the model\n","r = model.fit_generator(\n","  training_set,\n","  validation_data=test_set,\n","  epochs=5,\n","  steps_per_epoch=len(training_set),\n","  validation_steps=len(test_set)\n",")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/5\n","20/20 [==============================] - 512s 25s/step - loss: 2.1234 - accuracy: 0.4086 - val_loss: 0.7161 - val_accuracy: 0.7833\n","Epoch 2/5\n","20/20 [==============================] - 467s 23s/step - loss: 0.2820 - accuracy: 0.9062 - val_loss: 0.2503 - val_accuracy: 0.9000\n","Epoch 3/5\n","20/20 [==============================] - 466s 23s/step - loss: 0.0603 - accuracy: 0.9791 - val_loss: 0.4017 - val_accuracy: 0.8417\n","Epoch 4/5\n","20/20 [==============================] - 469s 24s/step - loss: 0.0354 - accuracy: 0.9973 - val_loss: 0.1921 - val_accuracy: 0.9250\n","Epoch 5/5\n","20/20 [==============================] - 469s 24s/step - loss: 0.0235 - accuracy: 0.9946 - val_loss: 0.1758 - val_accuracy: 0.9250\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"04CjZ3OPko4x","executionInfo":{"status":"ok","timestamp":1614788465820,"user_tz":-345,"elapsed":3424,"user":{"displayName":"Niraj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAcL5rAnMjJOT8ESeQyjVl6m_tQSW2HaqUoUfMSA=s64","userId":"16495485645589276387"}}},"source":["model.save('./drive/MyDrive/Facial Recognition/VGG19_model.h5')"],"execution_count":18,"outputs":[]}]}